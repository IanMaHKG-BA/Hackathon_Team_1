{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ICW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = str(input('User number'))\n",
    "icw = cadspy.DatabaseConnection(system='ICW', user=username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-\" style = \"border-radius:10px;border-width:3px;border-color:salmon;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "<font size=\"4\">Can't connect to ICW? Instructions on how to get access to it in the links below:\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: [Requesting Access to GitHub](https://baplc.sharepoint.com/sites/ask/SitePages/Requesting-Access-to-GitHub.aspx)\n",
    "\n",
    "Once your access to GitHub has been aproved, you need to:\n",
    "\n",
    "- Step 2: [Request access to British-Ent GitHub organisation](https://github.com/BritishAirways-Ent/insight-processes/blob/main/onboarding/Corporate_Directory_git.md)\n",
    "\n",
    "And\n",
    "\n",
    "- Step 3: [Setup Sagemaker Studio to access GitHub](https://github.com/BritishAirways-Ent/insight-processes/blob/main/onboarding/sagemaker_to_github_setup.md)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some packages to get you started. You don't have to use them but you may find them useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diplay all rows and cols when using 'dataframe'.head() or 'dataframe'.tail()\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Data\n",
    "\n",
    "#### S19 Lounge Eligibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "sel * from LDB_SBOX_OR.HACKATHON_OPS_LOUNGE_ELIGIBILITY\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_lounge_eligibility = icw.queryToDataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_eligibility.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_eligibility.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look to a particular flight number and date\n",
    "\n",
    "#mask = (df_lounge_eligibility['DISCHARGE_STN_CD'] == 'GCM   ') & (df_lounge_eligibility['GMT_UPLIFT_DT'] == dt.date(2019,9,12) )\n",
    "\n",
    "#df_lounge_eligibility[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S19 Flight info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "select * from LDB_SBOX_OR.HACKATHON_OPS_FLIGHT_INFO\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_flight_info = icw.queryToDataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_info.head(2)\n",
    "df_flight_info.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Station Code Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "select * from LDB_SBOX_OR.HACKATHON_OPS_COUNTRY_DECODE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_country = icw.queryToDataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Station Decodes from ICW reference table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are lots of missing destinations which are in lounge_elig but not in df_country.\n",
    "# They are all new (since ~2019) arrivals to Heathrow.\n",
    "# They are not in sandbox country dataset, but they are in a reference table on ICW.\n",
    "# Load that ICW reference table and filter for results not in our merged table, but that are in lounge_elig.\n",
    "# This should result in zero nan values.\n",
    "query = \"\"\"\n",
    "SELECT STN_CD, COUNTRY_CD, COUNTRY_NM, CORP_GEOG_CTRY_GRP_NM, CORP_GEOG_CONTINENT_NM\n",
    "FROM REF_GEOG_LOC_HIERARCHY\n",
    "\"\"\"\n",
    "df_additional_country_decodes=icw.queryToDataframe(query)\n",
    "df_additional_country_decodes.shape # we will remove destinations already in df_country and not in df_lounge_elig later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_country_decodes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aircraft Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "select * from LDB_SBOX_OR.HACKATHON_OPS_AC_TYPE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_acft_typ = icw.queryToDataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acft_typ.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acft_typ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acft_typ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* It is always worth checking the format of each of the columns in your dataframes before trying to do any work with them. To do so, you can make use of the `headers_and_first_row` function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headers_and_first_row(df):\n",
    "    '''\n",
    "    print headers and first row of a df to deal with data types\n",
    "    '''\n",
    "    \n",
    "    headers = df.columns\n",
    "    first_row = []\n",
    "\n",
    "    for col in headers:\n",
    "        first_row.append(df[col][0])\n",
    "    \n",
    "    dictionary = dict( zip( headers, first_row) )\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying headers_and_first_row to df_lounge_eligibility\n",
    "format_df = headers_and_first_row(df_lounge_eligibility)\n",
    "format_2 = headers_and_first_row(df_flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that some columns have blank spaces!\n",
    "format_df\n",
    "format_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-\" style = \"border-radius:10px;border-width:3px;border-color:lightblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "<font size=\"3\">**Exercise 1:** Pre-process **all** the tables above (df_lounge_eligibility, df_flight_info, df_country, df_acft_typ).\n",
    "\n",
    "</font>\n",
    "\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first strip all frames of spaces. We will then go through each frame to properly prepare it.\n",
    "\n",
    "We will then load some additional datasets that will be useful for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping strings\n",
    "\n",
    "tables = [df_lounge_eligibility,df_flight_info,df_country,df_acft_typ,df_additional_country_decodes]\n",
    "\n",
    "# Define a function that fine all string fields and remove all blak spaces\n",
    "def data_cleaning_string(df):\n",
    "    # Get names of all fields in a dataframe\n",
    "    fields = df.columns\n",
    "    # loop for all fields, if data type is string then remove blank spaces\n",
    "    for f in fields:\n",
    "        if type(df[f][0]) == str:\n",
    "            df[f] = df[f].str.strip()\n",
    "    return df\n",
    "\n",
    "for i,t in enumerate(tables):\n",
    "    tables[i] = data_cleaning_string(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplucates of flight_info\n",
    "\n",
    "# Sort the table\n",
    "df_flight_info = df_flight_info.sort_values(['GMT_PLND_DEP_TS','OPG_FLT_NO','GMT_ACT_DEP_TS'])\n",
    "# Remove all duplicates and keep the first rows of all duplicated\n",
    "df_flight_info = df_flight_info.drop_duplicates(subset = ['OPG_FLT_NO','GMT_PLND_DEP_TS'],keep = \"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Flight info\n",
    "# Ian's code to clean dataset - identify latest departure date for\n",
    "# duplicated flights and eliminate it.\n",
    "df_flight_info['GMT_PLND_DEP_DT'] = df_flight_info['GMT_PLND_DEP_TS'].dt.date\n",
    "df_flight_info['GMT_PLND_DEP_TIME'] = df_flight_info['GMT_PLND_DEP_TS'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Country\n",
    "df_country['DEP_STN_CD'] = df_country['ROUTE'].str.slice(0,3)\n",
    "df_country['ARR_STN_CD'] = df_country['ROUTE'].str.slice(3,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Aircraft type\n",
    "df_acft_typ.sort_values('FIRST_SEATS_QTY').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_eligibility.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div class=\"alert alert-\" style = \"border-radius:10px;border-width:3px;border-color:lightblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "<font size=\"3\">**Exercise 2:** Join the tables below\n",
    "   \n",
    "    - df_flight_info\n",
    "    - df_country\n",
    "    - df_acft_typ\n",
    "    \n",
    "to the table df_lounge_eligibility to generate a final dataset.\n",
    "\n",
    "</font>\n",
    "\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lounge_eligibility.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info = pd.merge(df_lounge_eligibility,# left table\n",
    "                                     df_flight_info, # right table\n",
    "                                     left_on = ['OPERATING_AIRLINE_CD','OPERATING_FLT_NO','GMT_UPLIFT_DT'], # left on? e.g. which columns from the left table are you joining on to?\n",
    "                                     right_on = ['OPG_ALN_CD','OPG_FLT_NO','GMT_PLND_DEP_DT'] , # right on? # left on? e.g. which columns from the right table are you joining on to?\n",
    "                                     how = \"left\" # how? e.g. left, right, inner,etc\n",
    "                                     )\n",
    "\n",
    "df_lounge_elig_flight_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!\n",
    "df_lounge_elig_flight_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rows with any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info[df_lounge_elig_flight_info.isna().any(axis=1)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight_info[df_flight_info['OPG_FLT_NO'] == 8642]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge `df_country` to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[headers_and_first_row(d) for d in [df_lounge_elig_flight_info,df_country]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional_country_decodes.columns\n",
    "df_country.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For efficiency, we should merge df_country and df_additional_country_decodes first.\n",
    "# Firstly, organise df_additional_country_decodes to have the same columns.\n",
    "# if statement to avoid throwing errors if column renaming from cell below has already been done.\n",
    "if 'STN_CD' in df_additional_country_decodes.columns:\n",
    "    station_code_col = 'STN_CD'\n",
    "elif 'ARR_STN_CD' in df_additional_country_decodes.columns:\n",
    "    station_code_col = 'ARR_STN_CD'\n",
    "df_additional_country_decodes = df_additional_country_decodes[~df_additional_country_decodes[station_code_col].isin(df_country['ARR_STN_CD'])]\n",
    "# for more efficiency, we can remove all those rows which are not needed as there are no lounge elig rows with that destinations.\n",
    "df_additional_country_decodes = df_additional_country_decodes[df_additional_country_decodes[station_code_col].isin(df_lounge_elig_flight_info['DISCHARGE_STN_CD'])]\n",
    "print(df_additional_country_decodes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need df_additional_country_decodes to have the same column names and order as df_country, ready for pd.concat.\n",
    "# By merging now, we eliminate the need to merge separately with df_lounge_elig.\n",
    "df_additional_country_decodes['ROUTE'] = 'LHR' + df_additional_country_decodes['STN_CD']\n",
    "df_additional_country_decodes['DEP_STN_CD'] = 'LHR'\n",
    "# We must ensure column names and order of df_additional_country_decodes match df_country.\n",
    "df_additional_country_decodes.rename(columns={'STN_CD':'ARR_STN_CD'},inplace=True)\n",
    "df_additional_country_decodes = df_additional_country_decodes[df_country.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat together.\n",
    "df_country = pd.concat([df_country,df_additional_country_decodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country = pd.merge(df_lounge_elig_flight_info,# left table\n",
    "                                     df_country, # right table\n",
    "                                     left_on = ['DISCHARGE_STN_CD'], # left on? e.g. which columns from the left table are you joining on to?\n",
    "                                     right_on = ['ARR_STN_CD'] , # right on? # left on? e.g. which columns from the right table are you joining on to?\n",
    "                                     how = \"left\" # how? e.g. left, right, inner,etc\n",
    "                                     )\n",
    "\n",
    "# df_lounge_elig_flight_info = df_lounge_elig_flight_info.drop_duplicates()\n",
    "\n",
    "df_lounge_elig_flight_info_country.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country[df_lounge_elig_flight_info_country['CORP_GEOG_CONTINENT_NM'].isna()].head(5)\n",
    "# There are no null values arising from lack of country data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid breaking anything, we first remove all values we do not need.\n",
    "# Firstly, remove those values in df_country.\n",
    "# then remove values not in df_lounge_elig.\n",
    "df_additional_country_decodes = df_additional_country_decodes[~df_additional_country_decodes['STN_CD'].isin(df_country['ARR_STN_CD'])]\n",
    "df_additional_country_decodes = df_additional_country_decodes[df_additional_country_decodes['STN_CD'].isin(df_lounge_elig_flight_info_country['DISCHARGE_STN_CD'])]\n",
    "df_additional_country_decodes.head(40)\n",
    "#df_lounge_elig_flight_info_country.merge(df_additional_country_decodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `df_acft_typ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country_acft_typ = pd.merge(\n",
    "    df_lounge_elig_flight_info_country,\n",
    "    df_acft_typ,\n",
    "    left_on = ['IATA_AC_TYP_CD','ACT_AC_TYP_CD'],\n",
    "    right_on = ['IATA_AC_TYP_CD','ACT_AC_TYP_CD'],\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "df_lounge_elig_flight_info_country_acft_typ.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country_acft_typ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country_acft_typ[df_lounge_elig_flight_info_country_acft_typ.isna().any(axis=1)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acft_typ[df_acft_typ['ACT_AC_TYP_CD'] == 'M4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More cleaning for columns redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_and_first_row(df_lounge_elig_flight_info_country_acft_typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop = ['GMT_PLND_DEP_TS','GMT_ACT_DEP_TS','OPG_ALN_CD','OPG_FLT_NO','ACT_DEP_STN_CD','PLND_ARR_STN_CD','ACT_ARR_STN_CD','GMT_UPLIFT_DT']\n",
    "\n",
    "# df_lounge_elig_flight_info_country_acft_typ = df_lounge_elig_flight_info_country_acft_typ.drop(columns = to_drop,)\n",
    "\n",
    "df_lounge_elig_flight_info_country_acft_typ.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lounge_elig_flight_info_country_acft_typ.to_csv('Merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<div class=\"alert alert-\" style = \"border-radius:10px;border-width:3px;border-color:lightblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "<font size=\"3\">Exercise 3: Based on S2019/S2023 data, provide a lookup table of Lounge eligibility assumptions that can be applied to a future schedule. To do so, answer each of the following questions in the Markdown cell provided below. \n",
    "\n",
    "- What level of granularity do you use?\n",
    "- What metric do you use to come up with Lounge eligibility profiles?\n",
    "\n",
    "    \n",
    "Note 1: **Provide evidence for your assumptions.** This can be in the form of tables, graphs, correlation matrix, etc.\n",
    "    \n",
    "Note 2: Make use of the examples below to give structure to your answer. Feel free to attend the Hackathon Clinics if you have any questions. \n",
    "</font>\n",
    "\n",
    "\n",
    "    \n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reasoning (Example 1)**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume:\n",
    "- Data has been preprocessed.\n",
    "- Data has been joined, and a final dataset has been created. This dataset is the result of joining the 4 tables.\n",
    "\n",
    "The final dataset has been called `df_lounge_elig_flight_info_country_acft_typ`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What level of granularity do you use?</u>\n",
    "- I have decided to split all flights in the network based on their aircraft type. I will therefore have a lookup table with two categories: Narrowbody and Widebody. \n",
    "\n",
    "<u>What metric do you use to come up with Lounge eligibility profiles?</u>\n",
    "- I have sumed up all the passengers by Aircraft Type, by Tier. Then I have divided them by the total number of passengers by Aircraft Type. For example:\n",
    "    - For NB aircrafts, and for Tier 1 passengers: In S19 we had 41,728 pax eligible for Tier 1 out of 7,222,830 pax flying on Narrowbody aircraft. This represents 0.6% of the costumers and I assume that this will be the number of costumers elegible for this specific Lounge in a future schedule.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that you want to group by\n",
    "list_groupby = ['WB_NB_CAT','Lounge_eligibility_tier']\n",
    "\n",
    "# grouping by WB_NB_CAT and Lounge_eligibility_tier\n",
    "df_groupby_wb_nb = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count = ('pax','sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_wb_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of pax by aircraft type\n",
    "\n",
    "# columns that you want to group by\n",
    "list_groupby = ['WB_NB_CAT']\n",
    "\n",
    "# grouping by WB_NB_CAT\n",
    "df_groupby_wb_nb_ttl = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count_ttl = ('pax','sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_wb_nb_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's left join df_groupby_wb_nb_ttl onto df_groupby_wb_nb\n",
    "# this adds a new column to the df_groupby_wb_nb table (pax_count_ttl) that will be used to get the percentage of passenger eligible by Tier\n",
    "\n",
    "df_groupby_wb_nb = pd.merge(df_groupby_wb_nb,\n",
    "                            df_groupby_wb_nb_ttl,\n",
    "                            on = ['WB_NB_CAT'],\n",
    "                            how = 'left'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_wb_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the percentage of pax elegible for each of the Tiers\n",
    "\n",
    "df_groupby_wb_nb['pax_eligible%'] = (df_groupby_wb_nb['pax_count'] / df_groupby_wb_nb['pax_count_ttl'] )*100 \n",
    "\n",
    "# getting the pax_elegible% column in the right format\n",
    "df_groupby_wb_nb['pax_eligible%'] = df_groupby_wb_nb['pax_eligible%'].map('{:,.1f}%'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping pax_count, pax_count_ttl columns - not needed anymore\n",
    "df_groupby_wb_nb.drop(columns=['pax_count','pax_count_ttl'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_wb_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'not eligible' rows - not needed anymore\n",
    "mask = df_groupby_wb_nb['Lounge_eligibility_tier'] == 'Not eligible'\n",
    "\n",
    "df_groupby_wb_nb = df_groupby_wb_nb[~mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Please save your final lookup table below in the form of a pandas dataframe. It must contain the categories you have come up with as rows, and the Tier 1, Tier 2, and Tier 3 percentage of costumers as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using set_index to come up with the final lookup table\n",
    "df_groupby_wb_nb = df_groupby_wb_nb.set_index(['WB_NB_CAT','Lounge_eligibility_tier'],drop = True).unstack('Lounge_eligibility_tier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final table\n",
    "df_groupby_wb_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Feedback:** This analysis provides a lookup table in the format needed to be input into a future schedule. Nevertheless, this analysis is too high level and you haven't provided any evidence for your assumptions. To further enhance your answer use insights from the data and provide evidence for your assumptions. Please find some ideas below: \n",
    "\n",
    "- Using the same categories (WB,NB), plot data overtime to better understand the peaks for the different lounges. \n",
    "- Is there a way to split Widebody into more categories? Do the Haul, Region, Time of Day, or Country play a role in the number of passengers that are eligible in Tier 1, Tier 2 and Tier 3? Etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "**Reasoning (Example 2)**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What level of granularity do you use?</u>\n",
    "- I have decided to split all flights in the network based on their flight number. I will therefore have a lookup table with a lot of categories as each flight number is a category. \n",
    "\n",
    "<u>What metric do you use to come up with Lounge eligibility profiles?</u>\n",
    "- I have sumed up all the passengers by flight number, by Tier. Then I have divided them by the total number of passengers flight number.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that you want to group by\n",
    "list_groupby = ['OPERATING_FLT_NO','DISCHARGE_STN_CD','Lounge_eligibility_tier']\n",
    "\n",
    "# grouping by OPERATING_FLT_NO, DISCHARGE_STN_CD and Lounge_eligibility_tier\n",
    "df_groupby_flt_no = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "# a look at the data\n",
    "df_groupby_flt_no.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of pax by OPERATING_FLT_NO and DISCHARGE_STN_CD\n",
    "\n",
    "# columns that you want to group by\n",
    "list_groupby = ['OPERATING_FLT_NO','DISCHARGE_STN_CD']\n",
    "\n",
    "# grouping by WB_NB_CAT\n",
    "df_groupby_flt_no_ttl = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count_ttl = ('pax','sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_flt_no_ttl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's left join df_groupby_flt_no_ttl onto df_groupby_flt_no\n",
    "# this adds a new column to the df_groupby_flt_no table (pax_count_ttl) that will be used to get the percentage of passenger eligible by Tier\n",
    "\n",
    "df_groupby_flt_no = pd.merge(df_groupby_flt_no,\n",
    "                            df_groupby_flt_no_ttl,\n",
    "                            on = ['OPERATING_FLT_NO','DISCHARGE_STN_CD'],\n",
    "                            how = 'left'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_flt_no.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the percentage of pax elegible for each of the Tiers\n",
    "\n",
    "df_groupby_flt_no['pax_eligible%'] = (df_groupby_flt_no['pax_count'] / df_groupby_flt_no['pax_count_ttl'] )*100 \n",
    "\n",
    "# getting the pax_elegible% column in the right format\n",
    "df_groupby_flt_no['pax_eligible%'] = df_groupby_flt_no['pax_eligible%'].map('{:,.1f}%'.format)\n",
    "\n",
    "# dropping pax_count, pax_count_ttl columns - not needed anymore\n",
    "df_groupby_flt_no.drop(columns=['pax_count','pax_count_ttl'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a look at the data\n",
    "df_groupby_flt_no.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'not eligible' rows - not needed anymore\n",
    "mask = df_groupby_flt_no['Lounge_eligibility_tier'] == 'Not eligible'\n",
    "\n",
    "df_groupby_flt_no = df_groupby_flt_no[~mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Please save your final lookup table below in the form of a pandas dataframe. It must contain the categories you have come up with as rows, and the Tier 1, Tier 2, and Tier 3 percentage of costumers as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using set_index to come up with the final lookup table\n",
    "df_groupby_flt_no = df_groupby_flt_no.set_index(['OPERATING_FLT_NO','DISCHARGE_STN_CD','Lounge_eligibility_tier'],drop = True).unstack('Lounge_eligibility_tier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final table\n",
    "df_groupby_flt_no.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Feedback:** This analysis goes at a very granular level, we might come up with missing values if we apply this lounge eligibility profiles to a future schedule. Here are some ideas to further enhance your answer: \n",
    "\n",
    "- What would happen if we fly to a new destination in the future? How do we ensure we have a lounge eligibility profile for this new route?\n",
    "- As you can see in the example above: Pax eligible for Tier 1 for the BKK flight is significantly different from the rest. What's the most used aircraft type for this route? And why it differs that much from the rest? Is it because of the route characteristics instead?\n",
    "- For SH routes, we might change the time of departure for a specific flight number from one year to the next. Explore the possibility of using a clasification that takes that into account, like using Time of Day instead of flight number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ian  \n",
    "First of all I would like to be able to split the data into 2019/23 data separately, which can be done by adding a year field into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original merged table\n",
    "headers_and_first_row(df_lounge_elig_flight_info_country_acft_typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lounge_elig_flight_info_country_acft_typ['GMT_PLND_DEPT_YR'] = df_lounge_elig_flight_info_country_acft_typ['GMT_PLND_DEP_DT'].year\n",
    "\n",
    "# headers_and_first_row(df_lounge_elig_flight_info_country_acft_typ)\n",
    "df_lounge_elig_flight_info_country_acft_typ['GMT_UPLIFT_YR'] = [dts.year for dts in df_lounge_elig_flight_info_country_acft_typ['GMT_UPLIFT_DT']]\n",
    "\n",
    "df_lounge_elig_flight_info_country_acft_typ.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that you want to group by\n",
    "list_groupby = ['GMT_UPLIFT_YR','Lounge_eligibility_tier']\n",
    "\n",
    "# grouping by OPERATING_FLT_NO, DISCHARGE_STN_CD and Lounge_eligibility_tier\n",
    "df_groupby_year = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "# a look at the data\n",
    "df_groupby_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn import datasets, linear_model\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers_and_first_row(df_lounge_elig_flight_info_country_acft_typ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the large tables to different tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged_T1 = df_lounge_elig_flight_info_country_acft_typ[df_lounge_elig_flight_info_country_acft_typ['Lounge_eligibility_tier'] == 'Tier 1'].reset_index()\n",
    "# df_merged_T2 = df_lounge_elig_flight_info_country_acft_typ[df_lounge_elig_flight_info_country_acft_typ['Lounge_eligibility_tier'] == 'Tier 2'].reset_index()\n",
    "# df_merged_T3 = df_lounge_elig_flight_info_country_acft_typ[df_lounge_elig_flight_info_country_acft_typ['Lounge_eligibility_tier'] == 'Tier 3'].reset_index()\n",
    "\n",
    "# df_merged_T1 = df_merged_T1.rename(columns={'pax':'Tier_1_pax'})\n",
    "# df_merged_T2 = df_merged_T2.rename(columns={'pax':'Tier_2_pax'})\n",
    "# df_merged_T3 = df_merged_T3.rename(columns={'pax':'Tier_3_pax'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged_T3.columns\n",
    "# headers_and_first_row(df_merged_T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.array([1,2,3])\n",
    "# x = np.array([-1,0,1])\n",
    "\n",
    "# # y = y.to_numpy()\n",
    "# # x = x.to_numpy().reshape(-1, 1)\n",
    "# x = x.reshape(-1,1)\n",
    "\n",
    "# # print(x.shape, y.shape)\n",
    "\n",
    "# regr = linear_model.LinearRegression()\n",
    "# regr.fit(x,y)\n",
    "\n",
    "# regr.coef_, regr.intercept_, regr.rank_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that you want to group by\n",
    "list_groupby = ['GMT_UPLIFT_YR']\n",
    "\n",
    "# grouping by OPERATING_FLT_NO, DISCHARGE_STN_CD and Lounge_eligibility_tier\n",
    "df_groupby_year_ttl = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count_ttl = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "# a look at the data\n",
    "df_groupby_year_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_year = pd.merge(df_groupby_year,\n",
    "                            df_groupby_year_ttl,\n",
    "                            on = ['GMT_UPLIFT_YR'],\n",
    "                            how = 'left'\n",
    "                           )\n",
    "\n",
    "df_groupby_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the percentage of pax elegible for each of the Tiers\n",
    "\n",
    "df_groupby_year['pax_eligible%'] = (df_groupby_year['pax_count'] / df_groupby_year['pax_count_ttl'] )*100 \n",
    "\n",
    "# getting the pax_elegible% column in the right format\n",
    "df_groupby_year['pax_eligible%'] = df_groupby_year['pax_eligible%'].map('{:,.1f}%'.format)\n",
    "\n",
    "# dropping pax_count, pax_count_ttl columns - not needed anymore\n",
    "df_groupby_year.drop(columns=['pax_count','pax_count_ttl'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_year = df_groupby_year[df_groupby_year['Lounge_eligibility_tier'] != \"Not eligible\"]\n",
    "\n",
    "df_groupby_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare by location and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that you want to group by\n",
    "list_groupby = ['CORP_GEOG_CONTINENT_NM','CORP_GEOG_CTRY_GRP_NM','GMT_UPLIFT_YR','Lounge_eligibility_tier']\n",
    "\n",
    "# grouping by OPERATING_FLT_NO, DISCHARGE_STN_CD and Lounge_eligibility_tier\n",
    "df_groupby_country_group_year = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "list_groupby = ['CORP_GEOG_CONTINENT_NM','CORP_GEOG_CTRY_GRP_NM','GMT_UPLIFT_YR']\n",
    "\n",
    "df_groupby_country_group_year_ttl = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count_ttl = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "df_groupby_country_group_year = pd.merge(df_groupby_country_group_year,\n",
    "                                         df_groupby_country_group_year_ttl,\n",
    "                                         on = list_groupby,\n",
    "                                         how = \"left\")\n",
    "\n",
    "df_groupby_country_group_year = df_groupby_country_group_year[df_groupby_country_group_year['Lounge_eligibility_tier'] != 'Not eligible']\n",
    "\n",
    "df_groupby_country_group_year['pax_eligible%'] = (df_groupby_country_group_year['pax_count'] / df_groupby_country_group_year['pax_count_ttl'] )*100 \n",
    "\n",
    "# getting the pax_elegible% column in the right format\n",
    "df_groupby_country_group_year['pax_eligible%'] = df_groupby_country_group_year['pax_eligible%'].map('{:,.1f}%'.format)\n",
    "\n",
    "# dropping pax_count, pax_count_ttl columns - not needed anymore\n",
    "df_groupby_country_group_year.drop(columns=['pax_count','pax_count_ttl'],inplace = True)\n",
    "\n",
    "df_groupby_country_group_year.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_country_group_year = df_groupby_country_group_year.set_index(['CORP_GEOG_CONTINENT_NM','CORP_GEOG_CTRY_GRP_NM','GMT_UPLIFT_YR','Lounge_eligibility_tier'],drop = True).unstack('Lounge_eligibility_tier')\n",
    "\n",
    "df_groupby_country_group_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that you want to group by\n",
    "list_groupby = ['CORP_GEOG_CONTINENT_NM','GMT_UPLIFT_YR','Lounge_eligibility_tier']\n",
    "\n",
    "# grouping by OPERATING_FLT_NO, DISCHARGE_STN_CD and Lounge_eligibility_tier\n",
    "df_groupby_cont_year = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "list_groupby = ['CORP_GEOG_CONTINENT_NM','GMT_UPLIFT_YR']\n",
    "\n",
    "df_groupby_cont_year_ttl = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                pax_count_ttl = ('pax','sum')\n",
    ").reset_index()\n",
    "\n",
    "df_groupby_cont_year = pd.merge(df_groupby_cont_year,\n",
    "                                df_groupby_cont_year_ttl,\n",
    "                                on = list_groupby,\n",
    "                                how = \"left\")\n",
    "\n",
    "df_groupby_cont_year = df_groupby_cont_year[df_groupby_cont_year['Lounge_eligibility_tier'] != 'Not eligible']\n",
    "\n",
    "df_groupby_cont_year['pax_eligible%'] = (df_groupby_cont_year['pax_count'] / df_groupby_cont_year['pax_count_ttl'] )*100 \n",
    "\n",
    "# getting the pax_elegible% column in the right format\n",
    "df_groupby_cont_year['pax_eligible%'] = df_groupby_cont_year['pax_eligible%'].map('{:,.1f}%'.format)\n",
    "\n",
    "# dropping pax_count, pax_count_ttl columns - not needed anymore\n",
    "df_groupby_cont_year.drop(columns=['pax_count','pax_count_ttl'],inplace = True)\n",
    "\n",
    "df_groupby_cont_year.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_cont_year = df_groupby_cont_year.set_index(['CORP_GEOG_CONTINENT_NM','GMT_UPLIFT_YR','Lounge_eligibility_tier'],drop = True).unstack('Lounge_eligibility_tier')\n",
    "\n",
    "df_groupby_cont_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_groupby = ['IATA_AC_TYP_CD','ACT_AC_TYP_CD','FIRST_SEATS_QTY','CLUB_SEATS_QTY','PREM_ECONOMY_SEATS_QTY','ECONOMY_SEATS_QTY','Lounge_eligibility_tier']\n",
    "\n",
    "# grouping by OPERATING_FLT_NO, DISCHARGE_STN_CD and Lounge_eligibility_tier\n",
    "df_groupby_acft = df_lounge_elig_flight_info_country_acft_typ.groupby(list_groupby).agg(\n",
    "                mean_pax_count = ('pax','mean')).reset_index()\n",
    "\n",
    "df_groupby_acft['mean_pax_count'] = df_groupby_acft['mean_pax_count'].map('{:,.1f}'.format)\n",
    "\n",
    "df_groupby_acft = df_groupby_acft[df_groupby_acft['Lounge_eligibility_tier'] != 'Not eligible']\n",
    "\n",
    "df_groupby_acft = df_groupby_acft.set_index(list_groupby,drop = True).unstack('Lounge_eligibility_tier')\n",
    "\n",
    "df_groupby_acft.fillna(0, inplace=True)\n",
    "\n",
    "df_groupby_acft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#\n",
    "# Your turn!!!\n",
    "#\n",
    "#--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What level of granularity do you use?</u>\n",
    "- ... (your answer here)\n",
    "\n",
    "<u>What metric do you use to come up with Lounge eligibility profiles?</u>\n",
    "- ... (your answer here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Please save your final lookup table below in the form of a pandas dataframe. It must contain the categories you have come up with as rows, and the Tier 1, Tier 2, and Tier 3 percentage of costumers as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "lcc_arn": "arn:aws:sagemaker:eu-west-1:954353547965:studio-lifecycle-config/install-cadspy-v1-8-1r2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
